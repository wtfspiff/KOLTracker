# ============================================================
# KOL Wallet Tracker - Configuration
# ============================================================

# --- Twitter / X (Private Reverse-Engineered API) ---
# Option 1: Username/Password login (recommended)
TWITTER_USERNAME=
TWITTER_PASSWORD=
TWITTER_EMAIL=
# Option 2: Auth tokens from browser (Developer Tools → Cookies)
TWITTER_AUTH_TOKEN=
TWITTER_CSRF_TOKEN=
# Cookie persistence file (auto-saved after login)
TWITTER_COOKIE_FILE=twitter_cookies.json
# Legacy: Official API bearer token (fallback, heavily rate-limited)
TWITTER_BEARER_TOKEN=
# Fallback: Nitter scraping (no auth needed, unreliable)
NITTER_INSTANCES=https://nitter.privacydev.net,https://nitter.poast.org

# --- Telegram ---
TELEGRAM_API_ID=
TELEGRAM_API_HASH=
TELEGRAM_PHONE=

# --- Solana RPCs ---
# Chainstack or any standard RPC works. Helius is preferred when available
# because it provides parsed swap data (DEX name, token amounts).
# If HELIUS_API_KEY is set, Helius is used for Solana scanning.
# If not, standard RPC is used (Chainstack, QuickNode, etc.)
SOLANA_RPC_URL=https://solana-mainnet.core.chainstack.com/YOUR_KEY
SOLANA_WS_URL=wss://solana-mainnet.core.chainstack.com/YOUR_KEY
# Helius gives parsed tx data — highly recommended but optional
HELIUS_API_KEY=
HELIUS_RPC_URL=https://mainnet.helius-rpc.com/?api-key=YOUR_KEY

# --- EVM RPCs (Chainstack recommended — no Etherscan needed for token scans) ---
# With Chainstack RPCs, token transfer scanning uses direct eth_getLogs (no rate limits).
# Native tx scanning still uses Etherscan as fallback (optional but recommended).
ETH_RPC_URL=https://ethereum-mainnet.core.chainstack.com/YOUR_KEY
BASE_RPC_URL=https://base-mainnet.core.chainstack.com/YOUR_KEY
BSC_RPC_URL=https://bsc-mainnet.core.chainstack.com/YOUR_KEY

# --- Block Explorer APIs (OPTIONAL with Chainstack RPCs) ---
# With Chainstack RPCs configured above, Etherscan is only used for:
# - Native tx history (ETH/BNB transfers) — no eth_getLogs equivalent
# - Address labeling fallback
# Without Chainstack, these are required for all EVM scanning.
SOLSCAN_API_KEY=
ETHERSCAN_API_KEY=
BASESCAN_API_KEY=
BSCSCAN_API_KEY=

# --- Price / Trade Data ---
BIRDEYE_API_KEY=
DEXSCREENER_API=https://api.dexscreener.com

# --- KOL Targets (comma-separated) ---
KOL_TWITTER_HANDLES=ansem,blknoiz06,CryptoGodJohn
KOL_TELEGRAM_CHANNELS=channel1,channel2
KOL_KNOWN_WALLETS=WalletAddr1:solana:main,0xAddr2:ethereum:trading

# --- Polling Intervals (seconds) ---
TWITTER_POLL_INTERVAL=60
TELEGRAM_POLL_INTERVAL=30
CHAIN_SCAN_INTERVAL=120
PATTERN_ANALYSIS_INTERVAL=300
FRESH_BUYER_SCAN_INTERVAL=15

# --- Detection Thresholds ---
WASH_WALLET_MIN_SCORE=0.4
AMOUNT_MATCH_TOLERANCE_PCT=3.0
FRESH_WALLET_AGE_HOURS=168
PRE_BUY_WINDOW_SECONDS=3600
POST_BUY_WINDOW_SECONDS=7200

# --- Database ---
DB_PATH=kol_tracker.db

# --- Dashboard ---
DASHBOARD_PORT=8080

# ============================================================
# AI / LLM Configuration
# ============================================================
# Choose ONE provider. Set AI_PROVIDER explicitly, or the system
# auto-detects from available API keys.

# --- Provider Selection (explicit) ---
# Options: "anthropic" | "ollama" | "openai"
# AI_PROVIDER=anthropic

# ─────────────────────────────────────────────
# OPTION 1: Anthropic Claude (recommended)
# ─────────────────────────────────────────────
# Cost: ~$20-40/mo light, ~$80-150/mo medium
ANTHROPIC_API_KEY=
# Primary model (complex tasks: wallet study, discovery)
AI_MODEL=claude-sonnet-4-20250514
# Fast model (simple tasks: post analysis, reclassify) — 12x cheaper
AI_MODEL_FAST=claude-haiku-4-5-20251001

# ─────────────────────────────────────────────
# OPTION 2: Ollama (local, completely FREE)
# ─────────────────────────────────────────────
# Install: curl -fsSL https://ollama.ai/install.sh | sh
# Start:   ollama serve
# The system auto-pulls models on first run.
# Requires: 8GB RAM (7B models), 16GB (13B), 32GB+ (70B)
#
# AI_PROVIDER=ollama
# OLLAMA_URL=http://localhost:11434
# OLLAMA_MODEL=llama3.1
# OLLAMA_AUTO_PULL=true
#
# Recommended models for this project:
#   llama3.1       - Good all-round (8B, ~4.7GB, fast)
#   llama3.1:70b   - Best quality (70B, ~40GB, slow)
#   mistral        - Fast + decent JSON output (7B)
#   deepseek-r1    - Strong reasoning (7B)
#   qwen2.5        - Good multilingual + code (7B)
#   gemma2         - Compact + fast (9B)

# ─────────────────────────────────────────────
# OPTION 3: OpenAI (alternative)
# ─────────────────────────────────────────────
# AI_PROVIDER=openai
# OPENAI_API_KEY=
# AI_MODEL=gpt-4o
# AI_MODEL_FAST=gpt-4o-mini

# --- AI Settings ---
AI_ANALYSIS_INTERVAL=600
AI_MAX_TOKENS=4096
